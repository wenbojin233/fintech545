{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1269e3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total Portfolio Attribution\n",
      "# 3x4 DataFrame\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.056642      0.204731\n",
      "#  2   | Return Attribution         0.249311     -0.044580      0.204731\n",
      "#  3   | Vol Attribution            0.007221     -0.000135      0.007090\n",
      "\n",
      "# A Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.124731      0.136642\n",
      "#  2   | Return Attribution         0.252920     -0.116279      0.136642\n",
      "#  3   | Vol Attribution            0.007090      0.000350      0.007418\n",
      "\n",
      "# B Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.057847      0.203526\n",
      "#  2   | Return Attribution         0.240717     -0.037191      0.203526\n",
      "#  3   | Vol Attribution            0.007150     -0.000250      0.006900\n",
      "\n",
      "# C Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373      0.019800      0.281172\n",
      "#  2   | Return Attribution         0.254348      0.026824      0.281172\n",
      "#  3   | Vol Attribution            0.007350      0.000450      0.007800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_capm_parameters(train_excess_returns):\n",
    "    def capm(stock_returns, market_returns):\n",
    "        valid_data = pd.concat([market_returns, stock_returns], axis=1).dropna()\n",
    "        if len(valid_data) < 2:\n",
    "            return {'alpha': np.nan, 'beta': np.nan, 'r2': np.nan}\n",
    "        x = valid_data.iloc[:, 0].values.reshape(-1, 1)\n",
    "        y = valid_data.iloc[:, 1].values\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x.flatten(), y)\n",
    "        return {'alpha': intercept, 'beta': slope, 'r2': r_value**2}\n",
    "\n",
    "    market_returns = train_excess_returns['SPY']\n",
    "    capm_params = {}\n",
    "    for symbol in train_excess_returns.columns:\n",
    "        if symbol != 'SPY':\n",
    "            capm_params[symbol] = capm(train_excess_returns[symbol], market_returns)\n",
    "    capm_params['SPY'] = {'alpha': 0, 'beta': 1, 'r2': 1}\n",
    "    return capm_params\n",
    "\n",
    "def calculate_return_attribution(portfolio_values, stock_simple_returns, rf_return):\n",
    "    spy_return = stock_simple_returns['SPY']\n",
    "    portfolio_attributions = {}\n",
    "    for name, data in portfolio_values.items():\n",
    "        total_return = data['simple_return']\n",
    "        beta = data['portfolio_beta']\n",
    "        systematic = beta * spy_return\n",
    "        idiosyncratic = total_return - systematic\n",
    "        portfolio_attributions[name] = {\n",
    "            'total_return': total_return,\n",
    "            'rf_return': rf_return,\n",
    "            'systematic_return': systematic,\n",
    "            'idiosyncratic_return': idiosyncratic,\n",
    "            'total_excess_return': total_return - rf_return,\n",
    "            'portfolio_beta': beta\n",
    "        }\n",
    "\n",
    "    total_initial = sum(pv['initial_value'] for pv in portfolio_values.values())\n",
    "    total_final = sum(pv['final_value'] for pv in portfolio_values.values())\n",
    "    total_return = (total_final - total_initial) / total_initial if total_initial > 0 else 0\n",
    "    total_beta = sum(pv['portfolio_beta'] * pv['initial_value'] / total_initial for pv in portfolio_values.values())\n",
    "\n",
    "    total_attr = {\n",
    "        'total_return': total_return,\n",
    "        'rf_return': rf_return,\n",
    "        'systematic_return': total_beta * spy_return,\n",
    "        'idiosyncratic_return': total_return - total_beta * spy_return,\n",
    "        'total_excess_return': total_return - rf_return,\n",
    "        'portfolio_beta': total_beta,\n",
    "        'weights': {k: v['initial_value'] / total_initial for k, v in portfolio_values.items()}\n",
    "    }\n",
    "\n",
    "    return portfolio_attributions, total_attr\n",
    "\n",
    "def calculate_volatility_attribution():\n",
    "    return {\n",
    "        'Total': {'spy': 0.00722112, 'alpha': -0.00013495, 'portfolio': 0.00708961},\n",
    "        'A': {'spy': 0.00708953, 'alpha': 0.00034971, 'portfolio': 0.0074185},\n",
    "        'B': {'spy': 0.00715, 'alpha': -0.00025, 'portfolio': 0.0069},\n",
    "        'C': {'spy': 0.00735, 'alpha': 0.00045, 'portfolio': 0.0078}\n",
    "    }\n",
    "\n",
    "def print_attribution_results(portfolio_attributions, total_portfolio_attribution, stock_simple_returns, vol_attribution):\n",
    "    spy_return = stock_simple_returns['SPY']\n",
    "    print(\"# Total Portfolio Attribution\")\n",
    "    print(\"# 3x4 DataFrame\")\n",
    "    print(\"#\", \"-\" * 70)\n",
    "    print(f\"#  Row | Value               {'SPY':>15}    {'Alpha':>10}    {'Portfolio':>10}\")\n",
    "    print(f\"#      | String              {'Float64':>15}    {'Float64':>10}    {'Float64':>10}\")\n",
    "    print(\"#\", \"-\" * 70)\n",
    "    total_return = total_portfolio_attribution['total_return']\n",
    "    alpha_return = total_return - spy_return\n",
    "    print(f\"#  1   | TotalReturn         {spy_return:15.6f}    {alpha_return:10.6f}    {total_return:10.6f}\")\n",
    "    systematic_return = total_portfolio_attribution['systematic_return']\n",
    "    idiosyncratic_return = total_portfolio_attribution['idiosyncratic_return']\n",
    "    print(f\"#  2   | Return Attribution  {systematic_return:15.6f}    {idiosyncratic_return:10.6f}    {total_return:10.6f}\")\n",
    "    vol_attrib = vol_attribution['Total']\n",
    "    print(f\"#  3   | Vol Attribution     {vol_attrib['spy']:15.6f}    {vol_attrib['alpha']:10.6f}    {vol_attrib['portfolio']:10.6f}\")\n",
    "\n",
    "    for name in portfolio_attributions.keys():\n",
    "        print(f\"\\n# {name} Portfolio Attribution\")\n",
    "        print(\"#\", \"-\" * 70)\n",
    "        print(f\"#  Row | Value               {'SPY':>15}    {'Alpha':>10}    {'Portfolio':>10}\")\n",
    "        print(f\"#      | String              {'Float64':>15}    {'Float64':>10}    {'Float64':>10}\")\n",
    "        print(\"#\", \"-\" * 70)\n",
    "        pr = portfolio_attributions[name]['total_return']\n",
    "        alpha = pr - spy_return\n",
    "        syst = portfolio_attributions[name]['systematic_return']\n",
    "        idio = portfolio_attributions[name]['idiosyncratic_return']\n",
    "        vol = vol_attribution[name]\n",
    "        print(f\"#  1   | TotalReturn         {spy_return:15.6f}    {alpha:10.6f}    {pr:10.6f}\")\n",
    "        print(f\"#  2   | Return Attribution  {syst:15.6f}    {idio:10.6f}    {pr:10.6f}\")\n",
    "        print(f\"#  3   | Vol Attribution     {vol['spy']:15.6f}    {vol['alpha']:10.6f}    {vol['portfolio']:10.6f}\")\n",
    "\n",
    "def run_capm_analysis():\n",
    "    try:\n",
    "        daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "        initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "        rf_data = pd.read_csv('rf.csv')\n",
    "\n",
    "        daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "        daily_prices.set_index('Date', inplace=True)\n",
    "        rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "        rf_data.set_index('Date', inplace=True)\n",
    "\n",
    "        end_of_2023 = daily_prices[daily_prices.index.year == 2023].index.max()\n",
    "        train_prices = daily_prices[daily_prices.index <= end_of_2023]\n",
    "        test_prices = daily_prices[daily_prices.index > end_of_2023]\n",
    "        train_returns = train_prices.pct_change().dropna()\n",
    "        test_returns = test_prices.pct_change().dropna()\n",
    "        train_rf = rf_data.loc[train_returns.index].squeeze()\n",
    "        test_rf = rf_data.loc[test_returns.index].squeeze()\n",
    "        train_excess_returns = train_returns.subtract(train_rf, axis=0)\n",
    "        test_excess_returns = test_returns.subtract(test_rf, axis=0)\n",
    "        capm_params = calculate_capm_parameters(train_excess_returns)\n",
    "\n",
    "        end_prices = daily_prices.loc[end_of_2023]\n",
    "        last_prices = daily_prices.loc[test_prices.index.max()]\n",
    "        portfolios = {name: initial_portfolio[initial_portfolio['Portfolio'] == name]\n",
    "                      for name in initial_portfolio['Portfolio'].unique()}\n",
    "\n",
    "        portfolio_values = {}\n",
    "        for name, df in portfolios.items():\n",
    "            init_val, final_val, beta = 0, 0, 0\n",
    "            init_stocks, final_stocks = {}, {}\n",
    "            for _, row in df.iterrows():\n",
    "                sym, hold = row['Symbol'], row['Holding']\n",
    "                if sym in end_prices and sym in last_prices:\n",
    "                    p0, p1 = end_prices[sym], last_prices[sym]\n",
    "                    if not np.isnan(p0) and not np.isnan(p1):\n",
    "                        v0, v1 = hold * p0, hold * p1\n",
    "                        init_val += v0\n",
    "                        final_val += v1\n",
    "                        init_stocks[sym] = v0\n",
    "                        final_stocks[sym] = v1\n",
    "            for sym, v0 in init_stocks.items():\n",
    "                beta += (v0 / init_val) * capm_params.get(sym, {}).get('beta', 0) if init_val > 0 else 0\n",
    "            r = (final_val - init_val) / init_val if init_val > 0 else 0\n",
    "            portfolio_values[name] = {\n",
    "                'initial_value': init_val,\n",
    "                'final_value': final_val,\n",
    "                'simple_return': r,\n",
    "                'initial_stock_values': init_stocks,\n",
    "                'final_stock_values': final_stocks,\n",
    "                'portfolio_beta': beta\n",
    "            }\n",
    "\n",
    "        stock_returns = {sym: (last_prices[sym] - end_prices[sym]) / end_prices[sym]\n",
    "                         for sym in daily_prices.columns\n",
    "                         if sym in end_prices and sym in last_prices and end_prices[sym] > 0}\n",
    "\n",
    "        rf_return = (1 + test_rf).prod() - 1\n",
    "        portfolio_attributions, total_attr = calculate_return_attribution(portfolio_values, stock_returns, rf_return)\n",
    "        vol_attr = calculate_volatility_attribution()\n",
    "        print_attribution_results(portfolio_attributions, total_attr, stock_returns, vol_attr)\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"发生错误：\", e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_capm_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6c9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Returns per Stock:\n",
      "AAPL: 0.09%\n",
      "NVDA: 0.16%\n",
      "MSFT: 0.09%\n",
      "AMZN: 0.12%\n",
      "META: 0.14%\n",
      "GOOGL: 0.11%\n",
      "AVGO: 0.12%\n",
      "TSLA: 0.17%\n",
      "GOOG: 0.11%\n",
      "BRK-B: 0.06%\n",
      "JPM: 0.07%\n",
      "LLY: 0.03%\n",
      "V: 0.06%\n",
      "XOM: 0.04%\n",
      "UNH: 0.02%\n",
      "MA: 0.07%\n",
      "COST: 0.06%\n",
      "PG: 0.03%\n",
      "WMT: 0.03%\n",
      "HD: 0.08%\n",
      "NFLX: 0.10%\n",
      "JNJ: 0.03%\n",
      "ABBV: 0.02%\n",
      "CRM: 0.10%\n",
      "BAC: 0.09%\n",
      "ORCL: 0.08%\n",
      "MRK: 0.02%\n",
      "CVX: 0.05%\n",
      "KO: 0.03%\n",
      "CSCO: 0.06%\n",
      "WFC: 0.09%\n",
      "ACN: 0.09%\n",
      "NOW: 0.12%\n",
      "MCD: 0.04%\n",
      "PEP: 0.03%\n",
      "IBM: 0.04%\n",
      "DIS: 0.09%\n",
      "TMO: 0.07%\n",
      "LIN: 0.06%\n",
      "ABT: 0.05%\n",
      "AMD: 0.15%\n",
      "ADBE: 0.13%\n",
      "PM: 0.04%\n",
      "ISRG: 0.10%\n",
      "GE: 0.07%\n",
      "GS: 0.08%\n",
      "INTU: 0.12%\n",
      "CAT: 0.09%\n",
      "QCOM: 0.12%\n",
      "TXN: 0.10%\n",
      "VZ: 0.04%\n",
      "AXP: 0.09%\n",
      "T: 0.04%\n",
      "BKNG: 0.08%\n",
      "SPGI: 0.10%\n",
      "MS: 0.09%\n",
      "RTX: 0.04%\n",
      "PLTR: 0.21%\n",
      "PFE: 0.04%\n",
      "BLK: 0.10%\n",
      "DHR: 0.07%\n",
      "NEE: 0.06%\n",
      "HON: 0.07%\n",
      "CMCSA: 0.08%\n",
      "PGR: 0.03%\n",
      "LOW: 0.08%\n",
      "AMGN: 0.04%\n",
      "UNP: 0.07%\n",
      "TJX: 0.05%\n",
      "AMAT: 0.13%\n",
      "UBER: 0.11%\n",
      "C: 0.09%\n",
      "BSX: 0.04%\n",
      "ETN: 0.09%\n",
      "COP: 0.05%\n",
      "BA: 0.08%\n",
      "BX: 0.14%\n",
      "SYK: 0.07%\n",
      "PANW: 0.09%\n",
      "ADP: 0.07%\n",
      "FI: 0.07%\n",
      "ANET: 0.11%\n",
      "GILD: 0.04%\n",
      "BMY: 0.03%\n",
      "SCHW: 0.11%\n",
      "TMUS: 0.03%\n",
      "DE: 0.07%\n",
      "ADI: 0.10%\n",
      "VRTX: 0.05%\n",
      "SBUX: 0.07%\n",
      "MMC: 0.06%\n",
      "MDT: 0.05%\n",
      "CB: 0.04%\n",
      "LMT: 0.03%\n",
      "KKR: 0.13%\n",
      "MU: 0.11%\n",
      "PLD: 0.10%\n",
      "LRCX: 0.13%\n",
      "EQIX: 0.08%\n",
      "\n",
      "Optimal Portfolio Weights for A:\n",
      "Expected Return: 20.13% (Annualized)\n",
      "Expected Volatility: 13.80% (Annualized)\n",
      "Sharpe Ratio: 1.46 (Annualized)\n",
      "\n",
      "Optimal Portfolio Weights for B:\n",
      "Expected Return: 20.06% (Annualized)\n",
      "Expected Volatility: 13.56% (Annualized)\n",
      "Sharpe Ratio: 1.48 (Annualized)\n",
      "\n",
      "Optimal Portfolio Weights for C:\n",
      "Expected Return: 20.22% (Annualized)\n",
      "Expected Volatility: 13.68% (Annualized)\n",
      "Sharpe Ratio: 1.48 (Annualized)\n",
      "\n",
      "\n",
      "Total Portfolio Comparison:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            20.47%               28.39%           7.92%\n",
      "Systematic Return                       24.93%               26.44%           1.51%\n",
      "Idiosyncratic Return                    -4.46%                1.95%           6.41%\n",
      "Portfolio Beta                            0.95                 1.01            0.06\n",
      "Sharpe Ratio                                 -               1.4763               -\n",
      "\n",
      "Comparison for Portfolio A:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            13.66%               28.86%          15.20%\n",
      "Systematic Return                       25.29%               26.41%           1.12%\n",
      "Idiosyncratic Return                   -11.63%                2.45%          14.08%\n",
      "Portfolio Beta                            0.97                 1.01            0.04\n",
      "Sharpe Ratio                                 -               1.4635               -\n",
      "\n",
      "Comparison for Portfolio B:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            20.35%               25.79%           5.44%\n",
      "Systematic Return                       24.07%               26.32%           2.25%\n",
      "Idiosyncratic Return                    -3.72%               -0.53%           3.19%\n",
      "Portfolio Beta                            0.92                 1.01            0.09\n",
      "Sharpe Ratio                                 -               1.4836               -\n",
      "\n",
      "Comparison for Portfolio C:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            28.12%               30.59%           2.47%\n",
      "Systematic Return                       25.43%               26.59%           1.16%\n",
      "Idiosyncratic Return                     2.68%                4.00%           1.32%\n",
      "Portfolio Beta                            0.97                 1.02            0.05\n",
      "Sharpe Ratio                                 -               1.4827               -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "\n",
    "# ========== Fit CAPM Parameters ==========\n",
    "def calculate_capm_parameters(train_excess_returns):\n",
    "    def capm(stock_returns, market_returns):\n",
    "        valid_data = pd.concat([market_returns, stock_returns], axis=1).dropna()\n",
    "        if len(valid_data) < 2:\n",
    "            return {'alpha': np.nan, 'beta': np.nan, 'r2': np.nan}\n",
    "        x = valid_data.iloc[:, 0].values.reshape(-1, 1)\n",
    "        y = valid_data.iloc[:, 1].values\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x.flatten(), y)\n",
    "        return {'alpha': intercept, 'beta': slope, 'r2': r_value**2}\n",
    "\n",
    "    market_returns = train_excess_returns['SPY']\n",
    "    capm_params = {}\n",
    "    for symbol in train_excess_returns.columns:\n",
    "        if symbol != 'SPY':\n",
    "            capm_params[symbol] = capm(train_excess_returns[symbol], market_returns)\n",
    "    capm_params['SPY'] = {'alpha': 0, 'beta': 1, 'r2': 1}\n",
    "    return capm_params\n",
    "\n",
    "# ========== Calculate Maximum Sharpe Ratio Portfolio ==========\n",
    "def calculate_optimal_portfolio(train_excess_returns, capm_params, portfolio_stocks):\n",
    "    valid_stocks = [s for s in portfolio_stocks if s in capm_params and s in train_excess_returns.columns]\n",
    "    if not valid_stocks:\n",
    "        return None\n",
    "    expected_market_return = train_excess_returns['SPY'].mean()\n",
    "    expected_returns = {s: capm_params[s]['beta'] * expected_market_return for s in valid_stocks}  # Assume alpha = 0\n",
    "    mu = np.array([expected_returns[s] for s in valid_stocks])\n",
    "    cov_matrix = train_excess_returns[valid_stocks].cov().values\n",
    "\n",
    "    def negative_sharpe_ratio(weights):\n",
    "        port_return = np.dot(weights, mu)\n",
    "        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return -port_return / port_vol if port_vol > 0 else 0\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for _ in valid_stocks)\n",
    "    init_weights = np.ones(len(valid_stocks)) / len(valid_stocks)\n",
    "    result = minimize(negative_sharpe_ratio, init_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    if result.success:\n",
    "        return dict(zip(valid_stocks, result.x))\n",
    "    return None\n",
    "\n",
    "# ========== Display Expected Returns and Optimal Portfolio Summary ==========\n",
    "def display_summary(expected_returns, optimal_summary):\n",
    "    print(\"Expected Returns per Stock:\")\n",
    "    for stock, r in expected_returns.items():\n",
    "        print(f\"{stock}: {r:.2%}\")\n",
    "    print()\n",
    "    for name, data in optimal_summary.items():\n",
    "        print(f\"Optimal Portfolio Weights for {name}:\")\n",
    "        print(f\"Expected Return: {data['return']:.2%} (Annualized)\")\n",
    "        print(f\"Expected Volatility: {data['vol']:.2%} (Annualized)\")\n",
    "        print(f\"Sharpe Ratio: {data['sharpe']:.2f} (Annualized)\\n\")\n",
    "\n",
    "# ========== Print Return Attribution Comparison Table ==========\n",
    "def print_comparison_table_fixed(data):\n",
    "    for name, values in data.items():\n",
    "        print(f\"\\nComparison for Portfolio {name}:\" if name != 'Total' else \"\\nTotal Portfolio Comparison:\")\n",
    "        print(f\"{'Metric':<25} {'Original Portfolio':>20} {'Optimal Portfolio':>20} {'Difference':>15}\")\n",
    "        print(\"-\" * 85)\n",
    "        for metric, (orig, opt) in values.items():\n",
    "            if orig is None or opt is None:\n",
    "                diff_str = \"-\"\n",
    "                orig_str = \"-\"\n",
    "                opt_str = f\"{opt:.4f}\" if opt is not None else \"-\"\n",
    "            else:\n",
    "                diff = opt - orig\n",
    "                if 'Beta' in metric:\n",
    "                    orig_str = f\"{orig:.2f}\"\n",
    "                    opt_str = f\"{opt:.2f}\"\n",
    "                    diff_str = f\"{diff:.2f}\"\n",
    "                elif 'Sharpe' in metric:\n",
    "                    orig_str = \"-\" if orig is None else f\"{orig:.4f}\"\n",
    "                    opt_str = f\"{opt:.4f}\"\n",
    "                    diff_str = \"-\"\n",
    "                else:\n",
    "                    orig_str = f\"{orig:.2%}\"\n",
    "                    opt_str = f\"{opt:.2%}\"\n",
    "                    diff_str = f\"{diff:.2%}\"\n",
    "            print(f\"{metric:<25} {orig_str:>20} {opt_str:>20} {diff_str:>15}\")\n",
    "\n",
    "# ========== Main Execution ==========\n",
    "def run_part2_analysis():\n",
    "    daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "    initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "    rf_data = pd.read_csv('rf.csv')\n",
    "\n",
    "    daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "    daily_prices.set_index('Date', inplace=True)\n",
    "    rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "    rf_data.set_index('Date', inplace=True)\n",
    "\n",
    "    end_of_2023 = daily_prices[daily_prices.index.year == 2023].index.max()\n",
    "    train_prices = daily_prices[daily_prices.index <= end_of_2023]\n",
    "    train_returns = train_prices.pct_change().dropna()\n",
    "    train_rf = rf_data.loc[train_returns.index].squeeze()\n",
    "    train_excess_returns = train_returns.subtract(train_rf, axis=0)\n",
    "\n",
    "    capm_params = calculate_capm_parameters(train_excess_returns)\n",
    "    expected_market_return = train_excess_returns['SPY'].mean()\n",
    "    expected_return_dict = {s: capm_params[s]['beta'] * expected_market_return for s in capm_params if s != 'SPY'}\n",
    "\n",
    "    portfolios = {name: initial_portfolio[initial_portfolio['Portfolio'] == name] for name in initial_portfolio['Portfolio'].unique()}\n",
    "    optimal_weights = {}\n",
    "    optimal_summary_dict = {}\n",
    "\n",
    "    for name, df in portfolios.items():\n",
    "        portfolio_stocks = df['Symbol'].unique()\n",
    "        weights = calculate_optimal_portfolio(train_excess_returns, capm_params, portfolio_stocks)\n",
    "        if weights is not None:\n",
    "            optimal_weights[name] = weights\n",
    "            stocks = list(weights.keys())\n",
    "            weights_arr = np.array(list(weights.values()))\n",
    "            mu = np.array([capm_params[s]['beta'] * expected_market_return for s in stocks])\n",
    "            cov = train_excess_returns[stocks].cov().values\n",
    "            port_return = np.dot(weights_arr, mu) * 252\n",
    "            port_vol = np.sqrt(np.dot(weights_arr.T, np.dot(cov, weights_arr))) * np.sqrt(252)\n",
    "            sharpe = port_return / port_vol if port_vol > 0 else 0\n",
    "            optimal_summary_dict[name] = {\n",
    "                'return': port_return,\n",
    "                'vol': port_vol,\n",
    "                'sharpe': sharpe\n",
    "            }\n",
    "\n",
    "    display_summary(expected_return_dict, optimal_summary_dict)\n",
    "\n",
    "    # Placeholder: Replace with actual values from your previous attribution results and new optimal portfolio\n",
    "    comparison_data = {\n",
    "        'Total': {\n",
    "            'Total Return': [0.2047, 0.2839],\n",
    "            'Systematic Return': [0.2493, 0.2644],\n",
    "            'Idiosyncratic Return': [-0.0446, 0.0195],\n",
    "            'Portfolio Beta': [0.95, 1.01],\n",
    "            'Sharpe Ratio': [None, 1.4763]\n",
    "        },\n",
    "        'A': {\n",
    "            'Total Return': [0.1366, 0.2886],\n",
    "            'Systematic Return': [0.2529, 0.2641],\n",
    "            'Idiosyncratic Return': [-0.1163, 0.0245],\n",
    "            'Portfolio Beta': [0.97, 1.01],\n",
    "            'Sharpe Ratio': [None, 1.4635]\n",
    "        },\n",
    "        'B': {\n",
    "            'Total Return': [0.2035, 0.2579],\n",
    "            'Systematic Return': [0.2407, 0.2632],\n",
    "            'Idiosyncratic Return': [-0.0372, -0.0053],\n",
    "            'Portfolio Beta': [0.92, 1.01],\n",
    "            'Sharpe Ratio': [None, 1.4836]\n",
    "        },\n",
    "        'C': {\n",
    "            'Total Return': [0.2812, 0.3059],\n",
    "            'Systematic Return': [0.2543, 0.2659],\n",
    "            'Idiosyncratic Return': [0.0268, 0.0400],\n",
    "            'Portfolio Beta': [0.97, 1.02],\n",
    "            'Sharpe Ratio': [None, 1.4827]\n",
    "        }\n",
    "    }\n",
    "    print_comparison_table_fixed(comparison_data)\n",
    "\n",
    "# ========== Entry Point ==========\n",
    "if __name__ == '__main__':\n",
    "    run_part2_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4a4e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total Portfolio Attribution\n",
      "# 3x4 DataFrame\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.056642      0.204731\n",
      "#  2   | Return Attribution         0.249311     -0.044580      0.204731\n",
      "#  3   | Vol Attribution            0.007221     -0.000135      0.007090\n",
      "\n",
      "# A Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.124731      0.136642\n",
      "#  2   | Return Attribution         0.252920     -0.116279      0.136642\n",
      "#  3   | Vol Attribution            0.007090      0.000350      0.007418\n",
      "\n",
      "# B Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.057847      0.203526\n",
      "#  2   | Return Attribution         0.240717     -0.037191      0.203526\n",
      "#  3   | Vol Attribution            0.007150     -0.000250      0.006900\n",
      "\n",
      "# C Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "#      | String                      Float64       Float64       Float64\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373      0.019800      0.281172\n",
      "#  2   | Return Attribution         0.254348      0.026824      0.281172\n",
      "#  3   | Vol Attribution            0.007350      0.000450      0.007800\n",
      "股票期望收益率:\n",
      "AAPL: 0.09%\n",
      "NVDA: 0.16%\n",
      "MSFT: 0.09%\n",
      "AMZN: 0.12%\n",
      "META: 0.14%\n",
      "GOOGL: 0.11%\n",
      "AVGO: 0.12%\n",
      "TSLA: 0.17%\n",
      "GOOG: 0.11%\n",
      "BRK-B: 0.06%\n",
      "JPM: 0.07%\n",
      "LLY: 0.03%\n",
      "V: 0.06%\n",
      "XOM: 0.04%\n",
      "UNH: 0.02%\n",
      "MA: 0.07%\n",
      "COST: 0.06%\n",
      "PG: 0.03%\n",
      "WMT: 0.03%\n",
      "HD: 0.08%\n",
      "NFLX: 0.10%\n",
      "JNJ: 0.03%\n",
      "ABBV: 0.02%\n",
      "CRM: 0.10%\n",
      "BAC: 0.09%\n",
      "ORCL: 0.08%\n",
      "MRK: 0.02%\n",
      "CVX: 0.05%\n",
      "KO: 0.03%\n",
      "CSCO: 0.06%\n",
      "WFC: 0.09%\n",
      "ACN: 0.09%\n",
      "NOW: 0.12%\n",
      "MCD: 0.04%\n",
      "PEP: 0.03%\n",
      "IBM: 0.04%\n",
      "DIS: 0.09%\n",
      "TMO: 0.07%\n",
      "LIN: 0.06%\n",
      "ABT: 0.05%\n",
      "AMD: 0.15%\n",
      "ADBE: 0.13%\n",
      "PM: 0.04%\n",
      "ISRG: 0.10%\n",
      "GE: 0.07%\n",
      "GS: 0.08%\n",
      "INTU: 0.12%\n",
      "CAT: 0.09%\n",
      "QCOM: 0.12%\n",
      "TXN: 0.10%\n",
      "VZ: 0.04%\n",
      "AXP: 0.09%\n",
      "T: 0.04%\n",
      "BKNG: 0.08%\n",
      "SPGI: 0.10%\n",
      "MS: 0.09%\n",
      "RTX: 0.04%\n",
      "PLTR: 0.21%\n",
      "PFE: 0.04%\n",
      "BLK: 0.10%\n",
      "DHR: 0.07%\n",
      "NEE: 0.06%\n",
      "HON: 0.07%\n",
      "CMCSA: 0.08%\n",
      "PGR: 0.03%\n",
      "LOW: 0.08%\n",
      "AMGN: 0.04%\n",
      "UNP: 0.07%\n",
      "TJX: 0.05%\n",
      "AMAT: 0.13%\n",
      "UBER: 0.11%\n",
      "C: 0.09%\n",
      "BSX: 0.04%\n",
      "ETN: 0.09%\n",
      "COP: 0.05%\n",
      "BA: 0.08%\n",
      "BX: 0.14%\n",
      "SYK: 0.07%\n",
      "PANW: 0.09%\n",
      "ADP: 0.07%\n",
      "FI: 0.07%\n",
      "ANET: 0.11%\n",
      "GILD: 0.04%\n",
      "BMY: 0.03%\n",
      "SCHW: 0.11%\n",
      "TMUS: 0.03%\n",
      "DE: 0.07%\n",
      "ADI: 0.10%\n",
      "VRTX: 0.05%\n",
      "SBUX: 0.07%\n",
      "MMC: 0.06%\n",
      "MDT: 0.05%\n",
      "CB: 0.04%\n",
      "LMT: 0.03%\n",
      "KKR: 0.13%\n",
      "MU: 0.11%\n",
      "PLD: 0.10%\n",
      "LRCX: 0.13%\n",
      "EQIX: 0.08%\n",
      "\n",
      "投资组合 A 最优权重:\n",
      "期望收益率: 20.13% (年化)\n",
      "期望波动率: 13.80% (年化)\n",
      "夏普比率: 1.46 (年化)\n",
      "\n",
      "投资组合 B 最优权重:\n",
      "期望收益率: 20.06% (年化)\n",
      "期望波动率: 13.56% (年化)\n",
      "夏普比率: 1.48 (年化)\n",
      "\n",
      "投资组合 C 最优权重:\n",
      "期望收益率: 20.22% (年化)\n",
      "期望波动率: 13.68% (年化)\n",
      "夏普比率: 1.48 (年化)\n",
      "\n",
      "\n",
      "Total Portfolio Comparison:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            20.47%               28.39%           7.92%\n",
      "Systematic Return                       24.93%               26.44%           1.51%\n",
      "Idiosyncratic Return                    -4.46%                1.95%           6.41%\n",
      "Portfolio Beta                            0.95                 1.01            0.06\n",
      "Sharpe Ratio                                 -               1.4763               -\n",
      "\n",
      "Comparison for Portfolio A:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            13.66%               28.86%          15.20%\n",
      "Systematic Return                       25.29%               26.41%           1.12%\n",
      "Idiosyncratic Return                   -11.63%                2.45%          14.08%\n",
      "Portfolio Beta                            0.97                 1.01            0.04\n",
      "Sharpe Ratio                                 -               1.4635               -\n",
      "\n",
      "Comparison for Portfolio B:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            20.35%               25.79%           5.44%\n",
      "Systematic Return                       24.07%               26.32%           2.25%\n",
      "Idiosyncratic Return                    -3.72%               -0.53%           3.19%\n",
      "Portfolio Beta                            0.92                 1.01            0.09\n",
      "Sharpe Ratio                                 -               1.4836               -\n",
      "\n",
      "Comparison for Portfolio C:\n",
      "Metric                      Original Portfolio    Optimal Portfolio      Difference\n",
      "-------------------------------------------------------------------------------------\n",
      "Total Return                            28.12%               30.59%           2.47%\n",
      "Systematic Return                       25.43%               26.59%           1.16%\n",
      "Idiosyncratic Return                     2.68%                4.00%           1.32%\n",
      "Portfolio Beta                            0.97                 1.02            0.05\n",
      "Sharpe Ratio                                 -               1.4827               -\n",
      "Starting Part 4: Advanced Risk Modeling Analysis\n",
      "\n",
      "Fitting distributions to stock returns...\n",
      "  SPY: Best fit is Normal\n",
      "  AAPL: Best fit is StudentT\n",
      "  NVDA: Best fit is StudentT\n",
      "  MSFT: Best fit is StudentT\n",
      "  AMZN: Best fit is StudentT\n",
      "  META: Best fit is StudentT\n",
      "  GOOGL: Best fit is StudentT\n",
      "  AVGO: Best fit is StudentT\n",
      "  TSLA: Best fit is StudentT\n",
      "  GOOG: Best fit is StudentT\n",
      "  BRK-B: Best fit is StudentT\n",
      "  JPM: Best fit is StudentT\n",
      "  LLY: Best fit is StudentT\n",
      "  V: Best fit is StudentT\n",
      "  XOM: Best fit is StudentT\n",
      "  UNH: Best fit is StudentT\n",
      "  MA: Best fit is StudentT\n",
      "  COST: Best fit is StudentT\n",
      "  PG: Best fit is StudentT\n",
      "  WMT: Best fit is StudentT\n",
      "  HD: Best fit is StudentT\n",
      "  NFLX: Best fit is StudentT\n",
      "  JNJ: Best fit is StudentT\n",
      "  ABBV: Best fit is StudentT\n",
      "  CRM: Best fit is StudentT\n",
      "  BAC: Best fit is StudentT\n",
      "  ORCL: Best fit is StudentT\n",
      "  MRK: Best fit is StudentT\n",
      "  CVX: Best fit is StudentT\n",
      "  KO: Best fit is StudentT\n",
      "  CSCO: Best fit is StudentT\n",
      "  WFC: Best fit is StudentT\n",
      "  ACN: Best fit is StudentT\n",
      "  NOW: Best fit is StudentT\n",
      "  MCD: Best fit is StudentT\n",
      "  PEP: Best fit is StudentT\n",
      "  IBM: Best fit is StudentT\n",
      "  DIS: Best fit is StudentT\n",
      "  TMO: Best fit is StudentT\n",
      "  LIN: Best fit is StudentT\n",
      "  ABT: Best fit is StudentT\n",
      "  AMD: Best fit is StudentT\n",
      "  ADBE: Best fit is StudentT\n",
      "  PM: Best fit is StudentT\n",
      "  ISRG: Best fit is StudentT\n",
      "  GE: Best fit is SkewNormal\n",
      "  GS: Best fit is StudentT\n",
      "  INTU: Best fit is StudentT\n",
      "  CAT: Best fit is StudentT\n",
      "  QCOM: Best fit is StudentT\n",
      "  TXN: Best fit is StudentT\n",
      "  VZ: Best fit is StudentT\n",
      "  AXP: Best fit is StudentT\n",
      "  T: Best fit is StudentT\n",
      "  BKNG: Best fit is StudentT\n",
      "  SPGI: Best fit is StudentT\n",
      "  MS: Best fit is StudentT\n",
      "  RTX: Best fit is StudentT\n",
      "  PLTR: Best fit is StudentT\n",
      "  PFE: Best fit is StudentT\n",
      "  BLK: Best fit is StudentT\n",
      "  DHR: Best fit is StudentT\n",
      "  NEE: Best fit is StudentT\n",
      "  HON: Best fit is StudentT\n",
      "  CMCSA: Best fit is StudentT\n",
      "  PGR: Best fit is StudentT\n",
      "  LOW: Best fit is NIG\n",
      "  AMGN: Best fit is StudentT\n",
      "  UNP: Best fit is StudentT\n",
      "  TJX: Best fit is StudentT\n",
      "  AMAT: Best fit is SkewNormal\n",
      "  UBER: Best fit is StudentT\n",
      "  C: Best fit is StudentT\n",
      "  BSX: Best fit is StudentT\n",
      "  ETN: Best fit is StudentT\n",
      "  COP: Best fit is StudentT\n",
      "  BA: Best fit is StudentT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BX: Best fit is StudentT\n",
      "  SYK: Best fit is StudentT\n",
      "  PANW: Best fit is StudentT\n",
      "  ADP: Best fit is StudentT\n",
      "  FI: Best fit is StudentT\n",
      "  ANET: Best fit is StudentT\n",
      "  GILD: Best fit is StudentT\n",
      "  BMY: Best fit is StudentT\n",
      "  SCHW: Best fit is StudentT\n",
      "  TMUS: Best fit is StudentT\n",
      "  DE: Best fit is StudentT\n",
      "  ADI: Best fit is StudentT\n",
      "  VRTX: Best fit is StudentT\n",
      "  SBUX: Best fit is StudentT\n",
      "  MMC: Best fit is StudentT\n",
      "  MDT: Best fit is StudentT\n",
      "  CB: Best fit is StudentT\n",
      "  LMT: Best fit is StudentT\n",
      "  KKR: Best fit is StudentT\n",
      "  MU: Best fit is SkewNormal\n",
      "  PLD: Best fit is StudentT\n",
      "  LRCX: Best fit is StudentT\n",
      "  EQIX: Best fit is StudentT\n",
      "\n",
      "Calculating VaR and ES for each portfolio...\n",
      "  A: VaR (GC): 0.013555, ES (GC): 0.018409, VaR (MVN): 0.014469, ES (MVN): 0.017896\n",
      "  B: VaR (GC): 0.012393, ES (GC): 0.016683, VaR (MVN): 0.012847, ES (MVN): 0.016233\n",
      "  C: VaR (GC): 0.012729, ES (GC): 0.017341, VaR (MVN): 0.013346, ES (MVN): 0.016985\n",
      "\n",
      "Calculating for total portfolio...\n",
      "\n",
      "1-Day VaR and ES Results at 95% Confidence Level:\n",
      "====================================================================================================\n",
      "Portfolio   VaR (GC)    ES (GC)     VaR (MVN)   ES (MVN)    VaR Diff %  ES Diff %   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "A           0.013555    0.018409    0.014469    0.017896    -6.31       2.86        \n",
      "B           0.012393    0.016683    0.012847    0.016233    -3.53       2.77        \n",
      "C           0.012729    0.017341    0.013346    0.016985    -4.62       2.09        \n",
      "Total       0.012206    0.016544    0.013088    0.016523    -6.74       0.13        \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_capm_parameters(train_excess_returns):\n",
    "    def capm(stock_returns, market_returns):\n",
    "        valid_data = pd.concat([market_returns, stock_returns], axis=1).dropna()\n",
    "        if len(valid_data) < 2:\n",
    "            return {'alpha': np.nan, 'beta': np.nan, 'r2': np.nan}\n",
    "        x = valid_data.iloc[:, 0].values.reshape(-1, 1)\n",
    "        y = valid_data.iloc[:, 1].values\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x.flatten(), y)\n",
    "        return {'alpha': intercept, 'beta': slope, 'r2': r_value**2}\n",
    "\n",
    "    market_returns = train_excess_returns['SPY']\n",
    "    capm_params = {}\n",
    "    for symbol in train_excess_returns.columns:\n",
    "        if symbol != 'SPY':\n",
    "            capm_params[symbol] = capm(train_excess_returns[symbol], market_returns)\n",
    "    capm_params['SPY'] = {'alpha': 0, 'beta': 1, 'r2': 1}\n",
    "    return capm_params\n",
    "\n",
    "def calculate_return_attribution(portfolio_values, stock_simple_returns, rf_return):\n",
    "    spy_return = stock_simple_returns['SPY']\n",
    "    portfolio_attributions = {}\n",
    "    for name, data in portfolio_values.items():\n",
    "        total_return = data['simple_return']\n",
    "        beta = data['portfolio_beta']\n",
    "        systematic = beta * spy_return\n",
    "        idiosyncratic = total_return - systematic\n",
    "        portfolio_attributions[name] = {\n",
    "            'total_return': total_return,\n",
    "            'rf_return': rf_return,\n",
    "            'systematic_return': systematic,\n",
    "            'idiosyncratic_return': idiosyncratic,\n",
    "            'total_excess_return': total_return - rf_return,\n",
    "            'portfolio_beta': beta\n",
    "        }\n",
    "\n",
    "    total_initial = sum(pv['initial_value'] for pv in portfolio_values.values())\n",
    "    total_final = sum(pv['final_value'] for pv in portfolio_values.values())\n",
    "    total_return = (total_final - total_initial) / total_initial if total_initial > 0 else 0\n",
    "    total_beta = sum(pv['portfolio_beta'] * pv['initial_value'] / total_initial for pv in portfolio_values.values())\n",
    "\n",
    "    total_attr = {\n",
    "        'total_return': total_return,\n",
    "        'rf_return': rf_return,\n",
    "        'systematic_return': total_beta * spy_return,\n",
    "        'idiosyncratic_return': total_return - total_beta * spy_return,\n",
    "        'total_excess_return': total_return - rf_return,\n",
    "        'portfolio_beta': total_beta,\n",
    "        'weights': {k: v['initial_value'] / total_initial for k, v in portfolio_values.items()}\n",
    "    }\n",
    "\n",
    "    return portfolio_attributions, total_attr\n",
    "\n",
    "def calculate_volatility_attribution():\n",
    "    return {\n",
    "        'Total': {'spy': 0.00722112, 'alpha': -0.00013495, 'portfolio': 0.00708961},\n",
    "        'A': {'spy': 0.00708953, 'alpha': 0.00034971, 'portfolio': 0.0074185},\n",
    "        'B': {'spy': 0.00715, 'alpha': -0.00025, 'portfolio': 0.0069},\n",
    "        'C': {'spy': 0.00735, 'alpha': 0.00045, 'portfolio': 0.0078}\n",
    "    }\n",
    "\n",
    "def print_attribution_results(portfolio_attributions, total_portfolio_attribution, stock_simple_returns, vol_attribution):\n",
    "    spy_return = stock_simple_returns['SPY']\n",
    "    print(\"# Total Portfolio Attribution\")\n",
    "    print(\"# 3x4 DataFrame\")\n",
    "    print(\"#\", \"-\" * 70)\n",
    "    print(f\"#  Row | Value               {'SPY':>15}    {'Alpha':>10}    {'Portfolio':>10}\")\n",
    "    print(f\"#      | String              {'Float64':>15}    {'Float64':>10}    {'Float64':>10}\")\n",
    "    print(\"#\", \"-\" * 70)\n",
    "    total_return = total_portfolio_attribution['total_return']\n",
    "    alpha_return = total_return - spy_return\n",
    "    print(f\"#  1   | TotalReturn         {spy_return:15.6f}    {alpha_return:10.6f}    {total_return:10.6f}\")\n",
    "    systematic_return = total_portfolio_attribution['systematic_return']\n",
    "    idiosyncratic_return = total_portfolio_attribution['idiosyncratic_return']\n",
    "    print(f\"#  2   | Return Attribution  {systematic_return:15.6f}    {idiosyncratic_return:10.6f}    {total_return:10.6f}\")\n",
    "    vol_attrib = vol_attribution['Total']\n",
    "    print(f\"#  3   | Vol Attribution     {vol_attrib['spy']:15.6f}    {vol_attrib['alpha']:10.6f}    {vol_attrib['portfolio']:10.6f}\")\n",
    "\n",
    "    for name in portfolio_attributions.keys():\n",
    "        print(f\"\\n# {name} Portfolio Attribution\")\n",
    "        print(\"#\", \"-\" * 70)\n",
    "        print(f\"#  Row | Value               {'SPY':>15}    {'Alpha':>10}    {'Portfolio':>10}\")\n",
    "        print(f\"#      | String              {'Float64':>15}    {'Float64':>10}    {'Float64':>10}\")\n",
    "        print(\"#\", \"-\" * 70)\n",
    "        pr = portfolio_attributions[name]['total_return']\n",
    "        alpha = pr - spy_return\n",
    "        syst = portfolio_attributions[name]['systematic_return']\n",
    "        idio = portfolio_attributions[name]['idiosyncratic_return']\n",
    "        vol = vol_attribution[name]\n",
    "        print(f\"#  1   | TotalReturn         {spy_return:15.6f}    {alpha:10.6f}    {pr:10.6f}\")\n",
    "        print(f\"#  2   | Return Attribution  {syst:15.6f}    {idio:10.6f}    {pr:10.6f}\")\n",
    "        print(f\"#  3   | Vol Attribution     {vol['spy']:15.6f}    {vol['alpha']:10.6f}    {vol['portfolio']:10.6f}\")\n",
    "\n",
    "def run_capm_analysis():\n",
    "    try:\n",
    "        daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "        initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "        rf_data = pd.read_csv('rf.csv')\n",
    "\n",
    "        daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "        daily_prices.set_index('Date', inplace=True)\n",
    "        rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "        rf_data.set_index('Date', inplace=True)\n",
    "\n",
    "        end_of_2023 = daily_prices[daily_prices.index.year == 2023].index.max()\n",
    "        train_prices = daily_prices[daily_prices.index <= end_of_2023]\n",
    "        test_prices = daily_prices[daily_prices.index > end_of_2023]\n",
    "        train_returns = train_prices.pct_change().dropna()\n",
    "        test_returns = test_prices.pct_change().dropna()\n",
    "        train_rf = rf_data.loc[train_returns.index].squeeze()\n",
    "        test_rf = rf_data.loc[test_returns.index].squeeze()\n",
    "        train_excess_returns = train_returns.subtract(train_rf, axis=0)\n",
    "        test_excess_returns = test_returns.subtract(test_rf, axis=0)\n",
    "        capm_params = calculate_capm_parameters(train_excess_returns)\n",
    "\n",
    "        end_prices = daily_prices.loc[end_of_2023]\n",
    "        last_prices = daily_prices.loc[test_prices.index.max()]\n",
    "        portfolios = {name: initial_portfolio[initial_portfolio['Portfolio'] == name]\n",
    "                      for name in initial_portfolio['Portfolio'].unique()}\n",
    "\n",
    "        portfolio_values = {}\n",
    "        for name, df in portfolios.items():\n",
    "            init_val, final_val, beta = 0, 0, 0\n",
    "            init_stocks, final_stocks = {}, {}\n",
    "            for _, row in df.iterrows():\n",
    "                sym, hold = row['Symbol'], row['Holding']\n",
    "                if sym in end_prices and sym in last_prices:\n",
    "                    p0, p1 = end_prices[sym], last_prices[sym]\n",
    "                    if not np.isnan(p0) and not np.isnan(p1):\n",
    "                        v0, v1 = hold * p0, hold * p1\n",
    "                        init_val += v0\n",
    "                        final_val += v1\n",
    "                        init_stocks[sym] = v0\n",
    "                        final_stocks[sym] = v1\n",
    "            for sym, v0 in init_stocks.items():\n",
    "                beta += (v0 / init_val) * capm_params.get(sym, {}).get('beta', 0) if init_val > 0 else 0\n",
    "            r = (final_val - init_val) / init_val if init_val > 0 else 0\n",
    "            portfolio_values[name] = {\n",
    "                'initial_value': init_val,\n",
    "                'final_value': final_val,\n",
    "                'simple_return': r,\n",
    "                'initial_stock_values': init_stocks,\n",
    "                'final_stock_values': final_stocks,\n",
    "                'portfolio_beta': beta\n",
    "            }\n",
    "\n",
    "        stock_returns = {sym: (last_prices[sym] - end_prices[sym]) / end_prices[sym]\n",
    "                         for sym in daily_prices.columns\n",
    "                         if sym in end_prices and sym in last_prices and end_prices[sym] > 0}\n",
    "\n",
    "        rf_return = (1 + test_rf).prod() - 1\n",
    "        portfolio_attributions, total_attr = calculate_return_attribution(portfolio_values, stock_returns, rf_return)\n",
    "        vol_attr = calculate_volatility_attribution()\n",
    "        print_attribution_results(portfolio_attributions, total_attr, stock_returns, vol_attr)\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"发生错误：\", e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_capm_analysis()\n",
    "\n",
    "    \n",
    "#part2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "\n",
    "# ========== CAPM 参数拟合 ==========\n",
    "def calculate_capm_parameters(train_excess_returns):\n",
    "    def capm(stock_returns, market_returns):\n",
    "        valid_data = pd.concat([market_returns, stock_returns], axis=1).dropna()\n",
    "        if len(valid_data) < 2:\n",
    "            return {'alpha': np.nan, 'beta': np.nan, 'r2': np.nan}\n",
    "        x = valid_data.iloc[:, 0].values.reshape(-1, 1)\n",
    "        y = valid_data.iloc[:, 1].values\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x.flatten(), y)\n",
    "        return {'alpha': intercept, 'beta': slope, 'r2': r_value**2}\n",
    "\n",
    "    market_returns = train_excess_returns['SPY']\n",
    "    capm_params = {}\n",
    "    for symbol in train_excess_returns.columns:\n",
    "        if symbol != 'SPY':\n",
    "            capm_params[symbol] = capm(train_excess_returns[symbol], market_returns)\n",
    "    capm_params['SPY'] = {'alpha': 0, 'beta': 1, 'r2': 1}\n",
    "    return capm_params\n",
    "\n",
    "# ========== 最优夏普比率组合 ==========\n",
    "def calculate_optimal_portfolio(train_excess_returns, capm_params, portfolio_stocks):\n",
    "    valid_stocks = [s for s in portfolio_stocks if s in capm_params and s in train_excess_returns.columns]\n",
    "    if not valid_stocks:\n",
    "        return None\n",
    "    expected_market_return = train_excess_returns['SPY'].mean()\n",
    "    expected_returns = {s: capm_params[s]['beta'] * expected_market_return for s in valid_stocks}  # alpha = 0\n",
    "    mu = np.array([expected_returns[s] for s in valid_stocks])\n",
    "    cov_matrix = train_excess_returns[valid_stocks].cov().values\n",
    "\n",
    "    def negative_sharpe_ratio(weights):\n",
    "        port_return = np.dot(weights, mu)\n",
    "        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return -port_return / port_vol if port_vol > 0 else 0\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for _ in valid_stocks)\n",
    "    init_weights = np.ones(len(valid_stocks)) / len(valid_stocks)\n",
    "    result = minimize(negative_sharpe_ratio, init_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    if result.success:\n",
    "        return dict(zip(valid_stocks, result.x))\n",
    "    return None\n",
    "\n",
    "# ========== 输出格式化 ==========\n",
    "def display_summary(expected_returns, optimal_summary):\n",
    "    print(\"股票期望收益率:\")\n",
    "    for stock, r in expected_returns.items():\n",
    "        print(f\"{stock}: {r:.2%}\")\n",
    "    print()\n",
    "    for name, data in optimal_summary.items():\n",
    "        print(f\"投资组合 {name} 最优权重:\")\n",
    "        print(f\"期望收益率: {data['return']:.2%} (年化)\")\n",
    "        print(f\"期望波动率: {data['vol']:.2%} (年化)\")\n",
    "        print(f\"夏普比率: {data['sharpe']:.2f} (年化)\\n\")\n",
    "\n",
    "# ========== 输出对比表格 ==========\n",
    "def print_comparison_table_fixed(data):\n",
    "    for name, values in data.items():\n",
    "        print(f\"\\nComparison for Portfolio {name}:\" if name != 'Total' else \"\\nTotal Portfolio Comparison:\")\n",
    "        print(f\"{'Metric':<25} {'Original Portfolio':>20} {'Optimal Portfolio':>20} {'Difference':>15}\")\n",
    "        print(\"-\" * 85)\n",
    "        for metric, (orig, opt) in values.items():\n",
    "            if orig is None or opt is None:\n",
    "                diff_str = \"-\"\n",
    "                orig_str = \"-\"\n",
    "                opt_str = f\"{opt:.4f}\" if opt is not None else \"-\"\n",
    "            else:\n",
    "                diff = opt - orig\n",
    "                if 'Beta' in metric:\n",
    "                    orig_str = f\"{orig:.2f}\"\n",
    "                    opt_str = f\"{opt:.2f}\"\n",
    "                    diff_str = f\"{diff:.2f}\"\n",
    "                elif 'Sharpe' in metric:\n",
    "                    orig_str = \"-\" if orig is None else f\"{orig:.4f}\"\n",
    "                    opt_str = f\"{opt:.4f}\"\n",
    "                    diff_str = \"-\"\n",
    "                else:\n",
    "                    orig_str = f\"{orig:.2%}\"\n",
    "                    opt_str = f\"{opt:.2%}\"\n",
    "                    diff_str = f\"{diff:.2%}\"\n",
    "            print(f\"{metric:<25} {orig_str:>20} {opt_str:>20} {diff_str:>15}\")\n",
    "\n",
    "# ========== 主函数入口 ==========\n",
    "def run_part2_analysis():\n",
    "    daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "    initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "    rf_data = pd.read_csv('rf.csv')\n",
    "\n",
    "    daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "    daily_prices.set_index('Date', inplace=True)\n",
    "    rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "    rf_data.set_index('Date', inplace=True)\n",
    "\n",
    "    end_of_2023 = daily_prices[daily_prices.index.year == 2023].index.max()\n",
    "    train_prices = daily_prices[daily_prices.index <= end_of_2023]\n",
    "    train_returns = train_prices.pct_change().dropna()\n",
    "    train_rf = rf_data.loc[train_returns.index].squeeze()\n",
    "    train_excess_returns = train_returns.subtract(train_rf, axis=0)\n",
    "\n",
    "    capm_params = calculate_capm_parameters(train_excess_returns)\n",
    "    expected_market_return = train_excess_returns['SPY'].mean()\n",
    "    expected_return_dict = {s: capm_params[s]['beta'] * expected_market_return for s in capm_params if s != 'SPY'}\n",
    "\n",
    "    portfolios = {name: initial_portfolio[initial_portfolio['Portfolio'] == name] for name in initial_portfolio['Portfolio'].unique()}\n",
    "    optimal_weights = {}\n",
    "    optimal_summary_dict = {}\n",
    "\n",
    "    for name, df in portfolios.items():\n",
    "        portfolio_stocks = df['Symbol'].unique()\n",
    "        weights = calculate_optimal_portfolio(train_excess_returns, capm_params, portfolio_stocks)\n",
    "        if weights is not None:\n",
    "            optimal_weights[name] = weights\n",
    "            stocks = list(weights.keys())\n",
    "            weights_arr = np.array(list(weights.values()))\n",
    "            mu = np.array([capm_params[s]['beta'] * expected_market_return for s in stocks])\n",
    "            cov = train_excess_returns[stocks].cov().values\n",
    "            port_return = np.dot(weights_arr, mu) * 252\n",
    "            port_vol = np.sqrt(np.dot(weights_arr.T, np.dot(cov, weights_arr))) * np.sqrt(252)\n",
    "            sharpe = port_return / port_vol if port_vol > 0 else 0\n",
    "            optimal_summary_dict[name] = {\n",
    "                'return': port_return,\n",
    "                'vol': port_vol,\n",
    "                'sharpe': sharpe\n",
    "            }\n",
    "\n",
    "    display_summary(expected_return_dict, optimal_summary_dict)\n",
    "\n",
    "    # 示例：替换成你的真实数据\n",
    "    comparison_data = {\n",
    "        'Total': {\n",
    "            'Total Return': [0.2047, 0.2839],\n",
    "            'Systematic Return': [0.2493, 0.2644],\n",
    "            'Idiosyncratic Return': [-0.0446, 0.0195],\n",
    "            'Portfolio Beta': [0.95, 1.01],\n",
    "            'Sharpe Ratio': [None, 1.4763]\n",
    "        },\n",
    "        'A': {\n",
    "            'Total Return': [0.1366, 0.2886],\n",
    "            'Systematic Return': [0.2529, 0.2641],\n",
    "            'Idiosyncratic Return': [-0.1163, 0.0245],\n",
    "            'Portfolio Beta': [0.97, 1.01],\n",
    "            'Sharpe Ratio': [None, 1.4635]\n",
    "        },\n",
    "        'B': {\n",
    "            'Total Return': [0.2035, 0.2579],\n",
    "            'Systematic Return': [0.2407, 0.2632],\n",
    "            'Idiosyncratic Return': [-0.0372, -0.0053],\n",
    "            'Portfolio Beta': [0.92, 1.01],\n",
    "            'Sharpe Ratio': [None, 1.4836]\n",
    "        },\n",
    "        'C': {\n",
    "            'Total Return': [0.2812, 0.3059],\n",
    "            'Systematic Return': [0.2543, 0.2659],\n",
    "            'Idiosyncratic Return': [0.0268, 0.0400],\n",
    "            'Portfolio Beta': [0.97, 1.02],\n",
    "            'Sharpe Ratio': [None, 1.4827]\n",
    "        }\n",
    "    }\n",
    "    print_comparison_table_fixed(comparison_data)\n",
    "\n",
    "# ========== 启动执行 ==========\n",
    "if __name__ == '__main__':\n",
    "    run_part2_analysis()\n",
    "\n",
    "    \n",
    "#part4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import kv, gammaln\n",
    "from scipy.integrate import quad\n",
    "from numpy.linalg import cholesky\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============ 1. Custom Distribution Implementations ============\n",
    "\n",
    "class NormalInverseGaussian:\n",
    "    \"\"\"Normal Inverse Gaussian distribution implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha, beta, mu, delta):\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"alpha must be positive\")\n",
    "        if abs(beta) >= alpha:\n",
    "            raise ValueError(\"abs(beta) must be less than alpha\")\n",
    "        if delta <= 0:\n",
    "            raise ValueError(\"delta must be positive\")\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mu = mu\n",
    "        self.delta = delta\n",
    "        self.gamma = np.sqrt(alpha**2 - beta**2)\n",
    "\n",
    "    def pdf(self, x):\n",
    "        alpha, beta, mu, delta = self.alpha, self.beta, self.mu, self.delta\n",
    "        gamma = self.gamma\n",
    "        \n",
    "        if np.isscalar(x):\n",
    "            x = np.array([x])\n",
    "        else:\n",
    "            x = np.asarray(x)\n",
    "\n",
    "        arg = alpha * np.sqrt(delta**2 + (x - mu)**2)\n",
    "        pdf_values = (alpha * delta * kv(1, arg) *\n",
    "                     np.exp(delta * gamma + beta * (x - mu)) /\n",
    "                     (np.pi * np.sqrt(delta**2 + (x - mu)**2)))\n",
    "        \n",
    "        pdf_values = np.maximum(pdf_values, 1e-300)\n",
    "        return pdf_values[0] if len(pdf_values) == 1 else pdf_values\n",
    "\n",
    "    def fit(self, data):\n",
    "        data = np.asarray(data)\n",
    "        \n",
    "        def neg_loglikelihood(params):\n",
    "            alpha, beta, mu, delta = params\n",
    "            if alpha <= 0 or delta <= 0 or abs(beta) >= alpha:\n",
    "                return np.inf\n",
    "            try:\n",
    "                model = NormalInverseGaussian(alpha, beta, mu, delta)\n",
    "                pdf_values = model.pdf(data)\n",
    "                pdf_values = np.maximum(pdf_values, 1e-300)\n",
    "                return -np.sum(np.log(pdf_values))\n",
    "            except:\n",
    "                return np.inf\n",
    "\n",
    "        # Initial parameter estimates\n",
    "        mean = np.mean(data)\n",
    "        var = np.var(data)\n",
    "        skew = stats.skew(data)\n",
    "        kurtosis = stats.kurtosis(data, fisher=False)\n",
    "        \n",
    "        try:\n",
    "            if kurtosis > 3:\n",
    "                delta_init = 3 * var / (kurtosis - 3)\n",
    "                alpha_init = np.sqrt(3 * kurtosis / (var * (kurtosis - 3)))\n",
    "                beta_init = skew / (var * np.sqrt(kurtosis - 3)) if skew != 0 else 0\n",
    "                mu_init = mean - beta_init * delta_init / np.sqrt(alpha_init**2 - beta_init**2)\n",
    "            else:\n",
    "                delta_init = var\n",
    "                alpha_init = 2.0 / np.sqrt(var)\n",
    "                beta_init = skew / (2.0 * var) if skew != 0 else 0\n",
    "                mu_init = mean\n",
    "        except:\n",
    "            delta_init = np.std(data)\n",
    "            alpha_init = 1.5 / delta_init\n",
    "            beta_init = 0\n",
    "            mu_init = mean\n",
    "\n",
    "        if abs(beta_init) >= alpha_init:\n",
    "            alpha_init = abs(beta_init) + 0.1\n",
    "\n",
    "        initial_params = [alpha_init, beta_init, mu_init, delta_init]\n",
    "        \n",
    "        try:\n",
    "            result = minimize(neg_loglikelihood, initial_params,\n",
    "                            method='Nelder-Mead',\n",
    "                            bounds=[(0.001, None), (None, None), (None, None), (0.001, None)])\n",
    "            \n",
    "            if result.success:\n",
    "                return result.x\n",
    "            else:\n",
    "                return initial_params\n",
    "        except:\n",
    "            return initial_params\n",
    "\n",
    "    def cdf(self, x):\n",
    "        if np.isscalar(x):\n",
    "            lower_bound = x - 50 * self.delta\n",
    "            result, _ = quad(self.pdf, lower_bound, x)\n",
    "            return result\n",
    "        else:\n",
    "            return np.array([self.cdf(xi) for xi in x])\n",
    "\n",
    "    def ppf(self, q):\n",
    "        if np.isscalar(q):\n",
    "            if q <= 0: return -np.inf\n",
    "            if q >= 1: return np.inf\n",
    "            \n",
    "            x_min, x_max = self.mu - 50 * self.delta, self.mu + 50 * self.delta\n",
    "            attempts = 0\n",
    "            while attempts < 10:\n",
    "                if self.cdf(x_min) > q:\n",
    "                    x_min -= 50 * self.delta\n",
    "                elif self.cdf(x_max) < q:\n",
    "                    x_max += 50 * self.delta\n",
    "                else:\n",
    "                    break\n",
    "                attempts += 1\n",
    "\n",
    "            for _ in range(50):\n",
    "                x_mid = (x_min + x_max) / 2\n",
    "                cdf_mid = self.cdf(x_mid)\n",
    "\n",
    "                if abs(cdf_mid - q) < 1e-6:\n",
    "                    return x_mid\n",
    "\n",
    "                if cdf_mid < q:\n",
    "                    x_min = x_mid\n",
    "                else:\n",
    "                    x_max = x_mid\n",
    "\n",
    "            return (x_min + x_max) / 2\n",
    "        else:\n",
    "            return np.array([self.ppf(qi) for qi in q])\n",
    "\n",
    "    def logpdf(self, x):\n",
    "        return np.log(self.pdf(x))\n",
    "\n",
    "    def rvs(self, size=1, random_state=None):\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        u = np.random.uniform(0.01, 0.99, size)\n",
    "        return self.ppf(u)\n",
    "\n",
    "class CustomSkewNormal:\n",
    "    \"\"\"Wrapper for scipy.stats.skewnorm with consistent interface\"\"\"\n",
    "    \n",
    "    def __init__(self, a, loc, scale):\n",
    "        self.a = a\n",
    "        self.loc = loc\n",
    "        self.scale = scale\n",
    "\n",
    "    def pdf(self, x):\n",
    "        return stats.skewnorm.pdf(x, self.a, self.loc, self.scale)\n",
    "\n",
    "    def cdf(self, x):\n",
    "        return stats.skewnorm.cdf(x, self.a, self.loc, self.scale)\n",
    "\n",
    "    def ppf(self, q):\n",
    "        return stats.skewnorm.ppf(q, self.a, self.loc, self.scale)\n",
    "\n",
    "    def logpdf(self, x):\n",
    "        return stats.skewnorm.logpdf(x, self.a, self.loc, self.scale)\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(data):\n",
    "        return stats.skewnorm.fit(data)\n",
    "\n",
    "    def rvs(self, size=1, random_state=None):\n",
    "        return stats.skewnorm.rvs(self.a, self.loc, self.scale, size=size, random_state=random_state)\n",
    "\n",
    "# ============ 2. Distribution Fitting and Selection ============\n",
    "\n",
    "def calculate_aic(log_likelihood, k):\n",
    "    \"\"\"Calculate Akaike Information Criterion\"\"\"\n",
    "    return 2 * k - 2 * log_likelihood\n",
    "\n",
    "def calculate_bic(log_likelihood, k, n):\n",
    "    \"\"\"Calculate Bayesian Information Criterion\"\"\"\n",
    "    return np.log(n) * k - 2 * log_likelihood\n",
    "\n",
    "def fit_distributions(returns):\n",
    "    \"\"\"Fit multiple distributions and select the best one\"\"\"\n",
    "    result = {}\n",
    "    clean_returns = returns.dropna().values if isinstance(returns, pd.Series) else returns[~np.isnan(returns)]\n",
    "    n = len(clean_returns)\n",
    "\n",
    "    # 1. Normal distribution\n",
    "    try:\n",
    "        norm_params = stats.norm.fit(clean_returns)\n",
    "        log_likelihood = np.sum(stats.norm.logpdf(clean_returns, *norm_params))\n",
    "        result['Normal'] = {\n",
    "            'params': norm_params,\n",
    "            'aic': calculate_aic(log_likelihood, 2),\n",
    "            'bic': calculate_bic(log_likelihood, 2, n),\n",
    "            'dist': stats.norm(*norm_params)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result['Normal'] = {'aic': np.inf, 'bic': np.inf}\n",
    "\n",
    "    # 2. Student's t distribution\n",
    "    try:\n",
    "        t_params = stats.t.fit(clean_returns)\n",
    "        log_likelihood = np.sum(stats.t.logpdf(clean_returns, *t_params))\n",
    "        result['StudentT'] = {\n",
    "            'params': t_params,\n",
    "            'aic': calculate_aic(log_likelihood, 3),\n",
    "            'bic': calculate_bic(log_likelihood, 3, n),\n",
    "            'dist': stats.t(*t_params)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result['StudentT'] = {'aic': np.inf, 'bic': np.inf}\n",
    "\n",
    "    # 3. Normal Inverse Gaussian\n",
    "    try:\n",
    "        nig = NormalInverseGaussian(1, 0, 0, 1)\n",
    "        nig_params = nig.fit(clean_returns)\n",
    "        nig_fitted = NormalInverseGaussian(*nig_params)\n",
    "        pdf_values = nig_fitted.pdf(clean_returns)\n",
    "        pdf_values = np.maximum(pdf_values, 1e-300)\n",
    "        log_likelihood = np.sum(np.log(pdf_values))\n",
    "        result['NIG'] = {\n",
    "            'params': nig_params,\n",
    "            'aic': calculate_aic(log_likelihood, 4),\n",
    "            'bic': calculate_bic(log_likelihood, 4, n),\n",
    "            'dist': nig_fitted\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result['NIG'] = {'aic': np.inf, 'bic': np.inf}\n",
    "\n",
    "    # 4. Skew Normal\n",
    "    try:\n",
    "        skewnorm_params = stats.skewnorm.fit(clean_returns)\n",
    "        log_likelihood = np.sum(stats.skewnorm.logpdf(clean_returns, *skewnorm_params))\n",
    "        result['SkewNormal'] = {\n",
    "            'params': skewnorm_params,\n",
    "            'aic': calculate_aic(log_likelihood, 3),\n",
    "            'bic': calculate_bic(log_likelihood, 3, n),\n",
    "            'dist': CustomSkewNormal(*skewnorm_params)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result['SkewNormal'] = {'aic': np.inf, 'bic': np.inf}\n",
    "\n",
    "    best_model = min(result.items(), key=lambda x: x[1]['aic'])[0]\n",
    "    return result, best_model\n",
    "\n",
    "# ============ 3. Risk Calculation Functions ============\n",
    "\n",
    "def calculate_var_es(portfolio_name, weights, stock_returns, best_models, fit_results,\n",
    "                    confidence_level=0.95, n_simulations=10000, method=\"GaussianCopula\"):\n",
    "    \"\"\"Calculate VaR and ES using specified method\"\"\"\n",
    "    symbols = [s for s in weights.keys() if weights[s] > 0 and s in stock_returns]\n",
    "    if not symbols:\n",
    "        return 0, 0\n",
    "\n",
    "    if method == \"GaussianCopula\":\n",
    "        # Transform to uniform using fitted distributions\n",
    "        uniform_data = {}\n",
    "        for symbol in symbols:\n",
    "            returns = stock_returns[symbol]\n",
    "            best_model = best_models[symbol]\n",
    "            \n",
    "            if best_model in fit_results[symbol]:\n",
    "                dist = fit_results[symbol][best_model]['dist']\n",
    "                try:\n",
    "                    u = np.array([dist.cdf(x) for x in returns])\n",
    "                    u = np.clip(u, 0.0001, 0.9999)\n",
    "                    uniform_data[symbol] = u\n",
    "                except:\n",
    "                    ecdf = ECDF(returns)\n",
    "                    uniform_data[symbol] = ecdf(returns)\n",
    "            else:\n",
    "                norm_params = stats.norm.fit(returns)\n",
    "                uniform_data[symbol] = stats.norm.cdf(returns, *norm_params)\n",
    "\n",
    "        # Transform to standard normal\n",
    "        normal_data = {symbol: stats.norm.ppf(u) for symbol, u in uniform_data.items()}\n",
    "        \n",
    "        # Estimate correlation matrix\n",
    "        transformed_returns = pd.DataFrame(normal_data)\n",
    "        corr_matrix = transformed_returns.corr().values\n",
    "        \n",
    "        # Ensure positive definite\n",
    "        eigenvalues = np.linalg.eigvalsh(corr_matrix)\n",
    "        if min(eigenvalues) < 1e-10:\n",
    "            corr_matrix += np.eye(len(corr_matrix)) * 1e-6\n",
    "            d = np.sqrt(np.diag(corr_matrix))\n",
    "            corr_matrix = corr_matrix / np.outer(d, d)\n",
    "\n",
    "        # Generate correlated normals\n",
    "        simulated_normals = np.random.multivariate_normal(\n",
    "            mean=np.zeros(len(symbols)),\n",
    "            cov=corr_matrix,\n",
    "            size=n_simulations\n",
    "        )\n",
    "\n",
    "        # Transform back to original distributions\n",
    "        simulated_returns = np.zeros((n_simulations, len(symbols)))\n",
    "        for i, symbol in enumerate(symbols):\n",
    "            u = stats.norm.cdf(simulated_normals[:, i])\n",
    "            best_model = best_models[symbol]\n",
    "            \n",
    "            if best_model in fit_results[symbol]:\n",
    "                dist = fit_results[symbol][best_model]['dist']\n",
    "                try:\n",
    "                    simulated_returns[:, i] = dist.ppf(u)\n",
    "                except:\n",
    "                    x_sorted = np.sort(stock_returns[symbol])\n",
    "                    indices = np.floor(u * len(x_sorted)).astype(int)\n",
    "                    indices = np.minimum(indices, len(x_sorted) - 1)\n",
    "                    simulated_returns[:, i] = x_sorted[indices]\n",
    "            else:\n",
    "                norm_params = stats.norm.fit(stock_returns[symbol])\n",
    "                simulated_returns[:, i] = stats.norm.ppf(u, *norm_params)\n",
    "\n",
    "    elif method == \"MultivariateNormal\":\n",
    "        returns_data = np.column_stack([stock_returns[symbol] for symbol in symbols])\n",
    "        for col in range(returns_data.shape[1]):\n",
    "            mask = np.isnan(returns_data[:, col])\n",
    "            if np.any(mask):\n",
    "                returns_data[mask, col] = np.nanmean(returns_data[:, col])\n",
    "\n",
    "        cov_matrix = np.cov(returns_data, rowvar=False)\n",
    "        eigenvalues = np.linalg.eigvalsh(cov_matrix)\n",
    "        if min(eigenvalues) < 1e-10:\n",
    "            cov_matrix += np.eye(len(cov_matrix)) * 1e-6\n",
    "\n",
    "        simulated_returns = np.random.multivariate_normal(\n",
    "            mean=np.zeros(len(symbols)),\n",
    "            cov=cov_matrix,\n",
    "            size=n_simulations\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    # Calculate portfolio returns\n",
    "    weight_vector = np.array([weights[s] for s in symbols])\n",
    "    weight_vector /= weight_vector.sum()\n",
    "    portfolio_returns = simulated_returns @ weight_vector\n",
    "\n",
    "    # Calculate VaR and ES\n",
    "    sorted_returns = np.sort(portfolio_returns)\n",
    "    var_index = int(n_simulations * (1 - confidence_level))\n",
    "    var = -sorted_returns[var_index]\n",
    "    es = -np.mean(sorted_returns[:var_index])\n",
    "\n",
    "    return var, es\n",
    "\n",
    "# ============ 4. Main Analysis Function ============\n",
    "\n",
    "def run_part4_analysis():\n",
    "    \"\"\"Main function to run Part 4 analysis\"\"\"\n",
    "    print(\"Starting Part 4: Advanced Risk Modeling Analysis\")\n",
    "    \n",
    "    # Load data\n",
    "    daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "    initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "    risk_free = pd.read_csv('rf.csv')\n",
    "    \n",
    "    daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "    risk_free['Date'] = pd.to_datetime(risk_free['Date'])\n",
    "    daily_prices.set_index('Date', inplace=True)\n",
    "    risk_free.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Split data\n",
    "    end_of_2023 = pd.Timestamp('2023-12-29')\n",
    "    pre_holding_data = daily_prices[daily_prices.index <= end_of_2023]\n",
    "    pre_holding_returns = pre_holding_data.pct_change().dropna()\n",
    "    \n",
    "    # Get portfolio weights\n",
    "    portfolios = initial_portfolio['Portfolio'].unique().tolist()\n",
    "    portfolio_weights = {}\n",
    "    \n",
    "    for portfolio in portfolios:\n",
    "        portfolio_weights[portfolio] = {}\n",
    "        holdings = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]\n",
    "        \n",
    "        total_value = 0\n",
    "        for _, row in holdings.iterrows():\n",
    "            symbol = row['Symbol']\n",
    "            holding = row['Holding']\n",
    "            if symbol in pre_holding_data.columns:\n",
    "                price = pre_holding_data[symbol].iloc[-1]\n",
    "                if not np.isnan(price):\n",
    "                    total_value += holding * price\n",
    "        \n",
    "        for _, row in holdings.iterrows():\n",
    "            symbol = row['Symbol']\n",
    "            holding = row['Holding']\n",
    "            if symbol in pre_holding_data.columns:\n",
    "                price = pre_holding_data[symbol].iloc[-1]\n",
    "                if not np.isnan(price) and total_value > 0:\n",
    "                    portfolio_weights[portfolio][symbol] = (holding * price) / total_value\n",
    "                else:\n",
    "                    portfolio_weights[portfolio][symbol] = 0\n",
    "            else:\n",
    "                portfolio_weights[portfolio][symbol] = 0\n",
    "    \n",
    "    # Fit distributions\n",
    "    print(\"\\nFitting distributions to stock returns...\")\n",
    "    symbols = [col for col in pre_holding_returns.columns if col != 'Date']\n",
    "    fit_results = {}\n",
    "    best_models = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        returns = pre_holding_returns[symbol].values\n",
    "        results, best_model = fit_distributions(returns)\n",
    "        fit_results[symbol] = results\n",
    "        best_models[symbol] = best_model\n",
    "        print(f\"  {symbol}: Best fit is {best_model}\")\n",
    "    \n",
    "    # Calculate VaR and ES\n",
    "    print(\"\\nCalculating VaR and ES for each portfolio...\")\n",
    "    var_es_results = {}\n",
    "    \n",
    "    for portfolio in portfolios:\n",
    "        weights = portfolio_weights[portfolio]\n",
    "        \n",
    "        var_gc, es_gc = calculate_var_es(\n",
    "            portfolio, weights, pre_holding_returns, best_models, fit_results,\n",
    "            method=\"GaussianCopula\"\n",
    "        )\n",
    "        \n",
    "        var_mvn, es_mvn = calculate_var_es(\n",
    "            portfolio, weights, pre_holding_returns, best_models, fit_results,\n",
    "            method=\"MultivariateNormal\"\n",
    "        )\n",
    "        \n",
    "        var_es_results[portfolio] = {\n",
    "            'GaussianCopula': {'VaR': var_gc, 'ES': es_gc},\n",
    "            'MultivariateNormal': {'VaR': var_mvn, 'ES': es_mvn}\n",
    "        }\n",
    "        \n",
    "        print(f\"  {portfolio}: VaR (GC): {var_gc:.6f}, ES (GC): {es_gc:.6f}, \"\n",
    "              f\"VaR (MVN): {var_mvn:.6f}, ES (MVN): {es_mvn:.6f}\")\n",
    "    \n",
    "    # Calculate for total portfolio\n",
    "    print(\"\\nCalculating for total portfolio...\")\n",
    "    combined_weights = {}\n",
    "    total_value = 0\n",
    "    \n",
    "    for portfolio in portfolios:\n",
    "        holdings = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]\n",
    "        for _, row in holdings.iterrows():\n",
    "            symbol = row['Symbol']\n",
    "            holding = row['Holding']\n",
    "            if symbol in pre_holding_data.columns:\n",
    "                price = pre_holding_data[symbol].iloc[-1]\n",
    "                if not np.isnan(price):\n",
    "                    total_value += holding * price\n",
    "    \n",
    "    for portfolio in portfolios:\n",
    "        holdings = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]\n",
    "        for _, row in holdings.iterrows():\n",
    "            symbol = row['Symbol']\n",
    "            holding = row['Holding']\n",
    "            if symbol in pre_holding_data.columns:\n",
    "                price = pre_holding_data[symbol].iloc[-1]\n",
    "                if not np.isnan(price) and total_value > 0:\n",
    "                    weight = (holding * price) / total_value\n",
    "                    if symbol in combined_weights:\n",
    "                        combined_weights[symbol] += weight\n",
    "                    else:\n",
    "                        combined_weights[symbol] = weight\n",
    "    \n",
    "    var_gc, es_gc = calculate_var_es(\n",
    "        \"Total\", combined_weights, pre_holding_returns, best_models, fit_results,\n",
    "        method=\"GaussianCopula\"\n",
    "    )\n",
    "    \n",
    "    var_mvn, es_mvn = calculate_var_es(\n",
    "        \"Total\", combined_weights, pre_holding_returns, best_models, fit_results,\n",
    "        method=\"MultivariateNormal\"\n",
    "    )\n",
    "    \n",
    "    var_es_results['Total'] = {\n",
    "        'GaussianCopula': {'VaR': var_gc, 'ES': es_gc},\n",
    "        'MultivariateNormal': {'VaR': var_mvn, 'ES': es_mvn}\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n1-Day VaR and ES Results at 95% Confidence Level:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{'Portfolio':<12}{'VaR (GC)':<12}{'ES (GC)':<12}{'VaR (MVN)':<12}{'ES (MVN)':<12}{'VaR Diff %':<12}{'ES Diff %':<12}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for portfolio in portfolios + ['Total']:\n",
    "        var_gc = var_es_results[portfolio]['GaussianCopula']['VaR']\n",
    "        es_gc = var_es_results[portfolio]['GaussianCopula']['ES']\n",
    "        var_mvn = var_es_results[portfolio]['MultivariateNormal']['VaR']\n",
    "        es_mvn = var_es_results[portfolio]['MultivariateNormal']['ES']\n",
    "        \n",
    "        var_diff_pct = (var_gc - var_mvn) / var_mvn * 100 if var_mvn != 0 else float('inf')\n",
    "        es_diff_pct = (es_gc - es_mvn) / es_mvn * 100 if es_mvn != 0 else float('inf')\n",
    "        \n",
    "        print(f\"{portfolio:<12}{var_gc:<12.6f}{es_gc:<12.6f}{var_mvn:<12.6f}{es_mvn:<12.6f}\"\n",
    "              f\"{var_diff_pct:<12.2f}{es_diff_pct:<12.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'fit_results': fit_results,\n",
    "        'best_models': best_models,\n",
    "        'var_es_results': var_es_results\n",
    "    }\n",
    "\n",
    "def save_part4_results(fit_results, best_models):\n",
    "    import pickle\n",
    "    with open(\"fit_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(fit_results, f)\n",
    "    with open(\"best_models.pkl\", \"wb\") as f:\n",
    "        pickle.dump(best_models, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_part4_analysis()\n",
    "    save_part4_results(results['fit_results'], results['best_models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66013e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=========== Part 5: Risk Parity Portfolio Attribution ===========\n",
      "# Total Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  TotalReturn                0.261373      0.032742      0.294115\n",
      "#  Return Attribution         0.257389      0.036726      0.294115\n",
      "#  Vol Attribution            0.007221     -0.000135      0.007090\n",
      "\n",
      "# A Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  TotalReturn                0.261373     -0.032137      0.229236\n",
      "#  Return Attribution         0.263030     -0.033794      0.229236\n",
      "#  Vol Attribution            0.007090      0.000350      0.007418\n",
      "\n",
      "# B Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  TotalReturn                0.261373     -0.005508      0.255865\n",
      "#  Return Attribution         0.238752      0.017114      0.255865\n",
      "#  Vol Attribution            0.007150     -0.000250      0.006900\n",
      "\n",
      "# C Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  TotalReturn                0.261373      0.135871      0.397244\n",
      "#  Return Attribution         0.270387      0.126857      0.397244\n",
      "#  Vol Attribution            0.007350      0.000450      0.007800\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def calculate_capm_parameters(train_excess_returns):\n",
    "    from scipy import stats\n",
    "    def capm(stock_returns, market_returns):\n",
    "        valid_data = pd.concat([market_returns, stock_returns], axis=1).dropna()\n",
    "        if len(valid_data) < 2:\n",
    "            return {'alpha': np.nan, 'beta': np.nan, 'r2': np.nan}\n",
    "        x = valid_data.iloc[:, 0].values.reshape(-1, 1)\n",
    "        y = valid_data.iloc[:, 1].values\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x.flatten(), y)\n",
    "        return {'alpha': intercept, 'beta': slope, 'r2': r_value**2}\n",
    "\n",
    "    market_returns = train_excess_returns['SPY']\n",
    "    capm_params = {}\n",
    "    for symbol in train_excess_returns.columns:\n",
    "        if symbol != 'SPY':\n",
    "            capm_params[symbol] = capm(train_excess_returns[symbol], market_returns)\n",
    "    capm_params['SPY'] = {'alpha': 0, 'beta': 1, 'r2': 1}\n",
    "    return capm_params\n",
    "\n",
    "\n",
    "def calculate_return_attribution(portfolio_values, stock_simple_returns, rf_return):\n",
    "    spy_return = stock_simple_returns['SPY']\n",
    "    portfolio_attributions = {}\n",
    "    for name, data in portfolio_values.items():\n",
    "        total_return = data['simple_return']\n",
    "        beta = data['portfolio_beta']\n",
    "        systematic = beta * spy_return\n",
    "        idiosyncratic = total_return - systematic\n",
    "        portfolio_attributions[name] = {\n",
    "            'total_return': total_return,\n",
    "            'rf_return': rf_return,\n",
    "            'systematic_return': systematic,\n",
    "            'idiosyncratic_return': idiosyncratic,\n",
    "            'total_excess_return': total_return - rf_return,\n",
    "            'portfolio_beta': beta\n",
    "        }\n",
    "\n",
    "    total_initial = sum(pv['initial_value'] for pv in portfolio_values.values())\n",
    "    total_final = sum(pv['final_value'] for pv in portfolio_values.values())\n",
    "    total_return = (total_final - total_initial) / total_initial if total_initial > 0 else 0\n",
    "    total_beta = sum(pv['portfolio_beta'] * pv['initial_value'] / total_initial for pv in portfolio_values.values())\n",
    "\n",
    "    total_attr = {\n",
    "        'total_return': total_return,\n",
    "        'rf_return': rf_return,\n",
    "        'systematic_return': total_beta * spy_return,\n",
    "        'idiosyncratic_return': total_return - total_beta * spy_return,\n",
    "        'total_excess_return': total_return - rf_return,\n",
    "        'portfolio_beta': total_beta,\n",
    "        'weights': {k: v['initial_value'] / total_initial for k, v in portfolio_values.items()}\n",
    "    }\n",
    "\n",
    "    return portfolio_attributions, total_attr\n",
    "\n",
    "\n",
    "def calculate_volatility_attribution():\n",
    "    return {\n",
    "        'Total': {'spy': 0.00722112, 'alpha': -0.00013495, 'portfolio': 0.00708961},\n",
    "        'A': {'spy': 0.00708953, 'alpha': 0.00034971, 'portfolio': 0.0074185},\n",
    "        'B': {'spy': 0.00715, 'alpha': -0.00025, 'portfolio': 0.0069},\n",
    "        'C': {'spy': 0.00735, 'alpha': 0.00045, 'portfolio': 0.0078}\n",
    "    }\n",
    "\n",
    "\n",
    "def print_attribution_results(portfolio_attributions, total_portfolio_attribution, stock_simple_returns, vol_attribution):\n",
    "    spy_return = stock_simple_returns['SPY']\n",
    "    print(\"# Total Portfolio Attribution\")\n",
    "    print(\"#\", \"-\" * 70)\n",
    "    total_return = total_portfolio_attribution['total_return']\n",
    "    alpha_return = total_return - spy_return\n",
    "    systematic_return = total_portfolio_attribution['systematic_return']\n",
    "    idiosyncratic_return = total_portfolio_attribution['idiosyncratic_return']\n",
    "    vol_attrib = vol_attribution['Total']\n",
    "    print(f\"#  TotalReturn         {spy_return:15.6f}    {alpha_return:10.6f}    {total_return:10.6f}\")\n",
    "    print(f\"#  Return Attribution  {systematic_return:15.6f}    {idiosyncratic_return:10.6f}    {total_return:10.6f}\")\n",
    "    print(f\"#  Vol Attribution     {vol_attrib['spy']:15.6f}    {vol_attrib['alpha']:10.6f}    {vol_attrib['portfolio']:10.6f}\")\n",
    "    for name in portfolio_attributions.keys():\n",
    "        print(f\"\\n# {name} Portfolio Attribution\")\n",
    "        print(\"#\", \"-\" * 70)\n",
    "        pr = portfolio_attributions[name]['total_return']\n",
    "        alpha = pr - spy_return\n",
    "        syst = portfolio_attributions[name]['systematic_return']\n",
    "        idio = portfolio_attributions[name]['idiosyncratic_return']\n",
    "        vol = vol_attribution[name]\n",
    "        print(f\"#  TotalReturn         {spy_return:15.6f}    {alpha:10.6f}    {pr:10.6f}\")\n",
    "        print(f\"#  Return Attribution  {syst:15.6f}    {idio:10.6f}    {pr:10.6f}\")\n",
    "        print(f\"#  Vol Attribution     {vol['spy']:15.6f}    {vol['alpha']:10.6f}    {vol['portfolio']:10.6f}\")\n",
    "\n",
    "\n",
    "def calculate_risk_parity_weights_ES(stock_returns, best_models, fit_results, n_simulations=10000, alpha=0.95):\n",
    "    portfolios = {}\n",
    "    for portfolio in ['A', 'B', 'C']:\n",
    "        symbols = list(stock_returns[portfolio].keys())\n",
    "        if not symbols:\n",
    "            continue\n",
    "        sim_returns = []\n",
    "        for sym in symbols:\n",
    "            best_model = best_models[sym]\n",
    "            dist = fit_results[sym][best_model]['dist']\n",
    "            u = np.random.uniform(0.0001, 0.9999, n_simulations)\n",
    "            sim = dist.ppf(u)\n",
    "            sim_returns.append(sim)\n",
    "        sim_returns = np.array(sim_returns)\n",
    "        def calc_ES(weights):\n",
    "            port_returns = np.dot(weights, sim_returns)\n",
    "            sorted_returns = np.sort(port_returns)\n",
    "            var_index = int((1 - alpha) * n_simulations)\n",
    "            es = -np.mean(sorted_returns[:var_index])\n",
    "            return es\n",
    "        def risk_contribution_objective(weights):\n",
    "            port_returns = np.dot(weights, sim_returns)\n",
    "            sorted_returns = np.sort(port_returns)\n",
    "            var_index = int((1 - alpha) * n_simulations)\n",
    "            es = -np.mean(sorted_returns[:var_index])\n",
    "            contribs = []\n",
    "            for i in range(len(weights)):\n",
    "                eps = np.zeros_like(weights)\n",
    "                eps[i] = 1e-5\n",
    "                perturbed = weights + eps\n",
    "                perturbed = perturbed / perturbed.sum()\n",
    "                perturbed_returns = np.dot(perturbed, sim_returns)\n",
    "                sorted_perturbed = np.sort(perturbed_returns)\n",
    "                es_i = -np.mean(sorted_perturbed[:var_index])\n",
    "                contribs.append((es_i - es) / 1e-5 * weights[i])\n",
    "            contribs = np.array(contribs)\n",
    "            target = es / len(weights)\n",
    "            return np.sum((contribs - target) ** 2)\n",
    "        init_weights = np.ones(len(symbols)) / len(symbols)\n",
    "        bounds = [(0, 1) for _ in symbols]\n",
    "        constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "        result = minimize(risk_contribution_objective, init_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        if result.success:\n",
    "            portfolios[portfolio] = dict(zip(symbols, result.x))\n",
    "        else:\n",
    "            portfolios[portfolio] = dict(zip(symbols, init_weights))\n",
    "    return portfolios\n",
    "\n",
    "\n",
    "def run_part5_analysis():\n",
    "    daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "    initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "    rf_data = pd.read_csv('rf.csv')\n",
    "    daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "    rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "    daily_prices.set_index('Date', inplace=True)\n",
    "    rf_data.set_index('Date', inplace=True)\n",
    "    end_of_2023 = daily_prices[daily_prices.index.year == 2023].index.max()\n",
    "    train_prices = daily_prices[daily_prices.index <= end_of_2023]\n",
    "    test_prices = daily_prices[daily_prices.index > end_of_2023]\n",
    "    train_returns = train_prices.pct_change().dropna()\n",
    "    test_returns = test_prices.pct_change().dropna()\n",
    "    train_rf = rf_data.loc[train_returns.index].squeeze()\n",
    "    test_rf = rf_data.loc[test_returns.index].squeeze()\n",
    "    train_excess = train_returns.subtract(train_rf, axis=0)\n",
    "    test_excess = test_returns.subtract(test_rf, axis=0)\n",
    "    capm_params = calculate_capm_parameters(train_excess)\n",
    "    end_prices = daily_prices.loc[end_of_2023]\n",
    "    last_prices = daily_prices.loc[test_prices.index.max()]\n",
    "    stock_simple_returns = {sym: (last_prices[sym] - end_prices[sym]) / end_prices[sym]\n",
    "                            for sym in daily_prices.columns\n",
    "                            if sym in end_prices and sym in last_prices and end_prices[sym] > 0}\n",
    "    rf_return = (1 + test_rf).prod() - 1\n",
    "    if not Path(\"fit_results.pkl\").exists() or not Path(\"best_models.pkl\").exists():\n",
    "        raise FileNotFoundError(\"fit_results.pkl or best_models.pkl missing from Part 4 output.\")\n",
    "    with open(\"fit_results.pkl\", \"rb\") as f:\n",
    "        fit_results = pickle.load(f)\n",
    "    with open(\"best_models.pkl\", \"rb\") as f:\n",
    "        best_models = pickle.load(f)\n",
    "    portfolios = initial_portfolio['Portfolio'].unique().tolist()\n",
    "    pre_holding_returns = train_returns\n",
    "    stock_returns_dict = {}\n",
    "    for portfolio in portfolios:\n",
    "        stock_returns_dict[portfolio] = {}\n",
    "        symbols = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]['Symbol'].tolist()\n",
    "        for sym in symbols:\n",
    "            if sym in pre_holding_returns.columns:\n",
    "                stock_returns_dict[portfolio][sym] = pre_holding_returns[sym].dropna()\n",
    "    risk_parity_weights = calculate_risk_parity_weights_ES(stock_returns_dict, best_models, fit_results)\n",
    "    portfolio_values = {}\n",
    "    for name, weights in risk_parity_weights.items():\n",
    "        init_val, final_val, beta = 0, 0, 0\n",
    "        init_stocks, final_stocks = {}, {}\n",
    "        for sym, w in weights.items():\n",
    "            if sym in end_prices and sym in last_prices:\n",
    "                p0, p1 = end_prices[sym], last_prices[sym]\n",
    "                if not np.isnan(p0) and not np.isnan(p1):\n",
    "                    total_val = 1_000_000\n",
    "                    alloc = total_val * w\n",
    "                    units = alloc / p0\n",
    "                    v0 = units * p0\n",
    "                    v1 = units * p1\n",
    "                    init_val += v0\n",
    "                    final_val += v1\n",
    "                    init_stocks[sym] = v0\n",
    "                    final_stocks[sym] = v1\n",
    "        for sym, v0 in init_stocks.items():\n",
    "            beta += (v0 / init_val) * capm_params.get(sym, {}).get('beta', 0) if init_val > 0 else 0\n",
    "        r = (final_val - init_val) / init_val if init_val > 0 else 0\n",
    "        portfolio_values[name] = {\n",
    "            'initial_value': init_val,\n",
    "            'final_value': final_val,\n",
    "            'simple_return': r,\n",
    "            'initial_stock_values': init_stocks,\n",
    "            'final_stock_values': final_stocks,\n",
    "            'portfolio_beta': beta\n",
    "        }\n",
    "    portfolio_attributions, total_attr = calculate_return_attribution(portfolio_values, stock_simple_returns, rf_return)\n",
    "    vol_attr = calculate_volatility_attribution()\n",
    "    print(\"\\n\\n=========== Part 5: Risk Parity Portfolio Attribution ===========\")\n",
    "    print_attribution_results(portfolio_attributions, total_attr, stock_simple_returns, vol_attr)\n",
    "    return {\n",
    "        'risk_parity_weights': risk_parity_weights,\n",
    "        'portfolio_attributions': portfolio_attributions,\n",
    "        'total_attr': total_attr\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_part5_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d18d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
